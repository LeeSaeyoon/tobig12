{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "\n",
    "# Import BeautifulSoup and requests module\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; InteSl Mac O X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "my_url = \"http://www.pythonscraping.com/exercises/exercise1.html\"\n",
    "\n",
    "# 사이트 요청 \n",
    "response = requests.get(my_url, headers = headers)\n",
    "\n",
    "# 요청의 status code 보기 (요청 상태 보는 것)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTML 보기\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find & FindAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title tag 찾기 \n",
    "soup = bs(response.text)\n",
    "title_tag = soup.find('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Useful Page'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title tag 내용 \n",
    "title_tag.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSS Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.pythonscraping.com/pages/warandpeace.html\"\n",
    "response = requests.get(url, headers=headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anna\\nPavlovna Scherer'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초록색 단어 찾기\n",
    "soup = bs(response.text, 'html.parser')\n",
    "soup.find('span', {\"class\":\"green\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "# 모든 초록색 단어 찾기 (findAll)\n",
    "green_word_tags = soup.findAll('span', class_='green')\n",
    "for green_word in green_word_tags:\n",
    "    print(green_word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, Prince, so Genoa and Lucca are now just family estates of the\n",
      "Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "if you still try to defend the infamies and horrors perpetrated by\n",
      "that Antichrist- I really believe he is Antichrist- I will have\n",
      "nothing more to do with you and you are no longer my friend, no longer\n",
      "my 'faithful slave,' as you call yourself! But how do you do? I see\n",
      "I have frightened you- sit down and tell me all the news.\n",
      "If you have nothing better to do, Count [or Prince], and if the\n",
      "prospect of spending an evening with a poor invalid is not too\n",
      "terrible, I shall be very charmed to see you tonight between 7 and 10-\n",
      "Annette Scherer.\n",
      "Heavens! what a virulent attack!\n",
      "First of all, dear friend, tell me how you are. Set your friend's\n",
      "mind at rest,\n",
      "Can one be well while suffering morally? Can one be calm in times\n",
      "like these if one has any feeling?\n",
      "You are\n",
      "staying the whole evening, I hope?\n",
      "And the fete at the English ambassador's? Today is Wednesday. I\n",
      "must put in an appearance there,\n",
      "My daughter is\n",
      "coming for me to take me there.\n",
      "I thought today's fete had been canceled. I confess all these\n",
      "festivities and fireworks are becoming wearisome.\n",
      "If they had known that you wished it, the entertainment would\n",
      "have been put off,\n",
      "Don't tease! Well, and what has been decided about Novosiltsev's\n",
      "dispatch? You know everything.\n",
      "What can one say about it?\n",
      "What has been decided? They have decided that\n",
      "Buonaparte has burnt his boats, and I believe that we are ready to\n",
      "burn ours.\n",
      "Oh, don't speak to me of Austria. Perhaps I don't understand\n",
      "things, but Austria never has wished, and does not wish, for war.\n",
      "She is betraying us! Russia alone must save Europe. Our gracious\n",
      "sovereign recognizes his high vocation and will be true to it. That is\n",
      "the one thing I have faith in! Our good and wonderful sovereign has to\n",
      "perform the noblest role on earth, and he is so virtuous and noble\n",
      "that God will not forsake him. He will fulfill his vocation and\n",
      "crush the hydra of revolution, which has become more terrible than\n",
      "ever in the person of this murderer and villain! We alone must\n",
      "avenge the blood of the just one.... Whom, I ask you, can we rely\n",
      "on?... England with her commercial spirit will not and cannot\n",
      "understand the Emperor Alexander's loftiness of soul. She has\n",
      "refused to evacuate Malta. She wanted to find, and still seeks, some\n",
      "secret motive in our actions. What answer did Novosiltsev get? None.\n",
      "The English have not understood and cannot understand the\n",
      "self-abnegation of our Emperor who wants nothing for himself, but only\n",
      "desires the good of mankind. And what have they promised? Nothing! And\n",
      "what little they have promised they will not perform! Prussia has\n",
      "always declared that Buonaparte is invincible, and that all Europe\n",
      "is powerless before him.... And I don't believe a word that Hardenburg\n",
      "says, or Haugwitz either. This famous Prussian neutrality is just a\n",
      "trap. I have faith only in God and the lofty destiny of our adored\n",
      "monarch. He will save Europe!\n",
      "I think,\n",
      "that if you had been\n",
      "sent instead of our dear Wintzingerode you would have captured the\n",
      "King of Prussia's consent by assault. You are so eloquent. Will you\n",
      "give me a cup of tea?\n",
      "In a moment. A propos,\n",
      "I am\n",
      "expecting two very interesting men tonight, le Vicomte de Mortemart,\n",
      "who is connected with the Montmorencys through the Rohans, one of\n",
      "the best French families. He is one of the genuine emigres, the good\n",
      "ones. And also the Abbe Morio. Do you know that profound thinker? He\n",
      "has been received by the Emperor. Had you heard?\n",
      "I shall be delighted to meet them,\n",
      "But tell me,\n",
      "is it true that the Dowager Empress wants Baron Funke\n",
      "to be appointed first secretary at Vienna? The baron by all accounts\n",
      "is a poor creature.\n",
      "Baron Funke has been recommended to the Dowager Empress by her\n",
      "sister,\n",
      "Now about your family. Do you know that since your daughter came\n",
      "out everyone has been enraptured by her? They say she is amazingly\n",
      "beautiful.\n",
      "I often think,\n",
      "I often think how unfairly sometimes the\n",
      "joys of life are distributed. Why has fate given you two such splendid\n",
      "children? I don't speak of Anatole, your youngest. I don't like\n",
      "him,\n",
      "Two such charming children. And really you appreciate\n",
      "them less than anyone, and so you don't deserve to have them.\n",
      "I can't help it,\n",
      "Lavater would have said I\n",
      "lack the bump of paternity.\n",
      "Don't joke; I mean to have a serious talk with you. Do you know I\n",
      "am dissatisfied with your younger son? Between ourselves\n",
      "he was mentioned at Her\n",
      "Majesty's and you were pitied....\n",
      "What would you have me do?\n",
      "You know I did all\n",
      "a father could for their education, and they have both turned out\n",
      "fools. Hippolyte is at least a quiet fool, but Anatole is an active\n",
      "one. That is the only difference between them.\n",
      "And why are children born to such men as you? If you were not a\n",
      "father there would be nothing I could reproach you with,\n",
      "I am your faithful slave and to you alone I can confess that my\n",
      "children are the bane of my life. It is the cross I have to bear. That\n",
      "is how I explain it to myself. It can't be helped!\n"
     ]
    }
   ],
   "source": [
    "# 빨간색 단어를 추출해봅시다 \n",
    "red_word_tags = soup.findAll('span', class_='red')\n",
    "for red_word in red_word_tags:\n",
    "    print(red_word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"green\">Anna\n",
       " Pavlovna Scherer</span>, <span class=\"green\">Empress Marya\n",
       " Fedorovna</span>, <span class=\"green\">Prince Vasili Kuragin</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">St. Petersburg</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Wintzingerode</span>, <span class=\"green\">King of Prussia</span>, <span class=\"green\">le Vicomte de Mortemart</span>, <span class=\"green\">Montmorencys</span>, <span class=\"green\">Rohans</span>, <span class=\"green\">Abbe Morio</span>, <span class=\"green\">the Emperor</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Dowager Empress Marya Fedorovna</span>, <span class=\"green\">the baron</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">Anna Pavlovna's</span>, <span class=\"green\">Her Majesty</span>, <span class=\"green\">Baron\n",
       " Funke</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\n",
       " Pavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anatole</span>, <span class=\"green\">the prince</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\n",
       " Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <span> 태그에 존재하는 빨간색과 초록색 글씨를 모두 추출해봅시다\n",
    "soup.findAll('span', {\"class\":\"red\", \"class\":\"green\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복습: <p> 에 있는 내용을 모두 리스트에 저장해봅시다. \n",
    "paragraph_tags = soup.findAll('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 사이트에 연습:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카페\n",
      "메일\n",
      "뉴스\n",
      "지도\n",
      "증권\n",
      "쇼핑\n",
      "카카오TV\n",
      "웹툰\n",
      "블로그\n",
      "브런치\n",
      "사전\n",
      "게임\n",
      "같이가치\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.daum.net'\n",
    "\n",
    "#Request 요청 (headers 추가 필수)\n",
    "response = requests.get(url, headers = headers)\n",
    "soup = bs(response.text)\n",
    "\n",
    "# 탭버튼이 담긴 정보 찾기 \n",
    "big_tab = soup.find('ul', {\"class\":\"list_mainsvc\"})\n",
    "big_tab.findAll('a')\n",
    "\n",
    "#findAll 도 해보기\n",
    "for i in big_tab.findAll('a'):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 태그 안에 있는 URL 정보를 얻고 싶다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://cafe.daum.net/'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find 문 이용시 \n",
    "tabs = big_tab.findAll('a')\n",
    "cafe = tabs[0]\n",
    "cafe['href']\n",
    "\n",
    "# FindALL 문 이용시 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent & Sibling 관계 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://pythonscraping.com/pages/page3.html\"\n",
    "response = requests.get(url)\n",
    "soup = bs(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 이미지 찾기 \n",
    "first_image_table = soup.find('img', {\"src\":\"../img/gifts/img1.jpg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>\n",
       "$15.00\n",
       "</td>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parent& sibling 관계를 이용하여\n",
    "# 다음 행에 있는 이미지 URL 구하기! \n",
    "first_image_table.parent.previous_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/logo.jpg\n",
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n"
     ]
    }
   ],
   "source": [
    "# 복습: findAll 문을 이용하여 모든 이미지 URl 구하기\n",
    "image_tags = soup.findAll('img')\n",
    "for i in image_tags:\n",
    "    print(i['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복습: CSS 문을 이용하여 볼드체 글씨를 모두 구하기 (class가 src인 경우 찾으면 됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img src=\"../img/gifts/img1.jpg\"/>,\n",
       " <img src=\"../img/gifts/img2.jpg\"/>,\n",
       " <img src=\"../img/gifts/img3.jpg\"/>,\n",
       " <img src=\"../img/gifts/img4.jpg\"/>,\n",
       " <img src=\"../img/gifts/img6.jpg\"/>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 정규식을 활용하여 gift 이미지 URL만 구하기 \n",
    "# 정규식은 제공 \n",
    "gift_regex = re.compile('img\\d.jpg')\n",
    "soup.findAll('img', {\"src\":gift_regex})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실제 크롤링 연습:  다음 영화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daum_movie_crawler(year):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; InteSl Mac O X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    main_url = 'https://movie.daum.net/boxoffice/yearly?year=' + str(year)\n",
    "    \n",
    "    # Initialize \n",
    "    data = []\n",
    "    cnt= 0 \n",
    "    \n",
    "    response = requests.get(main_url,headers=headers)\n",
    "    body_table = bs(response.text,'html.parser')\n",
    "    \n",
    "    #포스터 테이블 구하기 \n",
    "    poster_table = body_table.findAll('div', {\"class\":\"wrap_movie\"})\n",
    "\n",
    "    \n",
    "    #포스터 테이블을 looping \n",
    "    # 제목과 평론가 평점 찾기(과제)\n",
    "    for poster in poster_table:\n",
    "        title_tag = poster.find('a',{\"class\":\"name_movie #title\"})\n",
    "        data.append(title_tag.text)                                 \n",
    "                                                      \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2009-2019년도 데이터 얻기\n",
    "for i in range(2009, 2020):\n",
    "    daum_movie_crawler(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예외/ 오류 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    response = requests.get(my_url, headers=headers)\n",
    "except Exception as e:\n",
    "    print('Error occured while requesting')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "else:\n",
    "    print('Status code Error ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n위에 daum_movie_crawler 에 try-except 문을 추가해서\\n오류가 나는 것을 방지해보기 \\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "위에 daum_movie_crawler 에 try-except 문을 추가해서\n",
    "오류가 나는 것을 방지해보기 \n",
    "\"\"\"\n",
    "# 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_url = \"https://www.ncbi.nlm.nih.gov/pubmed/?term=wine\"\n",
    "browser = webdriver.Chrome() #혹은 .Firefox() , .Safari()\n",
    "browser.get(your_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로 가기 버튼 xpath 를 이용해 찾기 \n",
    "next_button = browser.find_element_by_xpath('//*[@id=\"EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_Pager.Page\"]')\n",
    "\n",
    "# 버튼 클릭 \n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#논문 태그 찾기 (class 이용)\n",
    "paper_tags = browser.find_elements_by_class_name('rprt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effects of different discoloration challenges and whitening treatments on dental hard tissues and composite resin restorations.\n",
      "Functionalized erythrocyte-derived optical nanoparticles to target ephrin-B2 ligands.\n",
      "Discrete choice experiments with multiple price vectors for products sold in a wide price range.\n",
      "Arcobacter cryaerophilus Isolated From New Zealand Mussels Harbor a Putative Virulence Plasmid.\n",
      "Characterization of the Key Aroma Compounds in Marselan Wine by Gas Chromatography-Olfactometry, Quantitative Measurements, Aroma Recombination, and Omission Tests.\n",
      "Optimal Alcohol Taxes for Australia.\n",
      "Combination of schisandrin and nootkatone exerts neuroprotective effect in Alzheimer's disease mice model.\n",
      "Volatile profile of reduced alcohol wines fermented with selected non-Saccharomyces yeasts under different aeration conditions.\n",
      "The expression, secretion and activity of the aspartic protease MpAPr1 in Metschnikowia pulcherrima IWBT Y1123.\n",
      "Port-wine stain, limb hypertrophy, dilated veins and blue sclera: Klippel-Trenaunay syndrome.\n",
      "Chemical typicality of South American red wines classified according to their volatile and phenolic compounds using multivariate analysis.\n",
      "Non volatile constituents of the vermouth ingredient Artemisia vallesiaca.\n",
      "Roles of glial ion transporters in brain diseases.\n",
      "Regional discrimination of Australian Shiraz wine volatome by GCxGC-TOF-MS.\n",
      "Expression of Leukocytes Following Myocardial Infarction in Rats is Modulated by Moderate White Wine Consumption.\n",
      "A new analytical method to measure S-methyl-L-methionine in grape juice reveals the influence of yeast on dimethyl sulfide production during fermentation.\n",
      "Impact of dealcoholization on quality properties in white wine at various alcohol content levels.\n",
      "Correction to: Four new cucurbitane-type triterpenes from Momordica charantia L. with their cytotoxic activities and protective effects on H2O2-damaged pancreatic cells.\n",
      "Weighted Correlation Network Analysis (WGCNA) Reveals the Hub Role of Protein Ubiquitination in the Acquisition of Desiccation Tolerance in Boea Hygrometrica.\n",
      "Pre-diagnosis alcohol consumption and mortality risk among black women and white women with invasive breast cancer.\n"
     ]
    }
   ],
   "source": [
    "# 각 태그의 제목 (tag_name 이용)\n",
    "for paper in paper_tags :\n",
    "    print(paper.find_element_by_tag_name('a').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5 페이지동안 논문제목을 크롤링한뒤 \n",
    "논문제목이 담긴 리스트를 반환하는 함수를 구현해보세요 (다음 페이지로 넘어가기전에 0-1초간 휴식)\n",
    "\"\"\"\n",
    "\n",
    "browser = webdriver.Chrome() \n",
    "browser.get(your_url)\n",
    "\n",
    "for page in range(1,6):\n",
    "    print(\"Currently on page \", page)\n",
    "    paper_tags = browser.find_elements_by_class_name('rprt')\n",
    "    for paper in paper_tags:\n",
    "        # paper 찾기\n",
    "        # data.append(paper 제목)\n",
    "    # next_button 찾기\n",
    "    # next_button 클릭\n",
    "    \n",
    "    sleep(random.uniform(3,10)) # 0-1초 간 휴식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "# 인스타그램 '영화' 검색 결과 url\n",
    "url = \"https://www.instagram.com/explore/tags/영화/?hl=ko\"\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(url)\n",
    "\n",
    "data = []\n",
    "for article in range(5000):\n",
    "    article_tags = browser.find_elements_by_class_name('클래스')\n",
    "    for article in article_tags:\n",
    "        lst = []\n",
    "        # 게시글 내용 찾아서 리스트에 append\n",
    "        content = article.find_element_by_tag_name('클래스').text\n",
    "        lst.append(content)\n",
    "        # 게시자 계정 찾아서 리스트에 append\n",
    "        account = article.find_element_by_tag_name('클래스').get_attribute('title')\n",
    "        lst.append(account)\n",
    "        # 날짜 찾아서 리스트에 append\n",
    "        date = article.find_element_by_tag_name('클래스').get_attribute('datetime')\n",
    "        lst.append(date)\n",
    "        # 댓글 단 계정 찾아서 리스트에 append\n",
    "        reply_account = article.find_element_by_tag_name('클래스').get_attribute('title')\n",
    "        lst.append(reply_account)\n",
    "        # 댓글 내용 찾아서 리스트에 append\n",
    "        reply_content = article.find_element_by_tag_name('클래스').text\n",
    "        lst.append(reply_content)\n",
    "    \n",
    "    # 리스트 data에 append\n",
    "    data.append(lst)\n",
    "    # 다음 버튼 찾기\n",
    "    next_button = browser.find_element_by_xpath('path명')\n",
    "    # 다음 버튼 클릭\n",
    "    next_button.click\n",
    "    \n",
    "    # 3-10초 간 휴식\n",
    "    sleep(random.uniform(3,10)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
